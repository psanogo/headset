{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e653c9c-a109-4c7e-850b-f250d567f8a6",
   "metadata": {},
   "source": [
    "# Lab: Detecting AI Bias in a Hiring Scenario\n",
    "\n",
    "In this lab, you'll train two logistic regression models to predict hiring decisions and investigate whether gender introduces bias into the model's predictions.\n",
    "\n",
    "**Dataset:** `hiring_dataset.csv`  \n",
    "**Features:** `Experience`, `Gender`  \n",
    "**Target:** `Shortlisted` (Selected / Not Selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e52b0f-aedd-4edd-aa83-fa699131a56e",
   "metadata": {},
   "source": [
    "# Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce904a-b992-4f82-9714-3a1c4f8e629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"hiring_dataset.csv\")\n",
    "\n",
    "# Preview\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3ae7b-11d8-49e0-9a76-983d3a67087b",
   "metadata": {},
   "source": [
    "# Encode Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef7308-d0dd-46b2-afcb-5f6ba03a7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Gender: Male = 0, Female = 1\n",
    "df['Gender_encoded'] = df['Gender'].map({'Male': 0, 'Female': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6743da6-98b2-4d3c-bc02-248ba231f5ee",
   "metadata": {},
   "source": [
    "# Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0d428-f72d-4ecd-8707-d7da9c1c1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X_with_gender = df[['Gender_encoded', 'Experience']]\n",
    "X_without_gender = df[['Experience']]\n",
    "y = df['Shortlisted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab7688-6802-49a1-b385-d1586db30e52",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c65325-b8e6-44b3-be19-e578673b9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train_wg, X_test_wg, y_train, y_test = train_test_split(X_with_gender, y, test_size=0.3, random_state=42)\n",
    "X_train_wo, X_test_wo, _, _ = train_test_split(X_without_gender, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa7385-645b-46d2-9dc9-258a5218ed2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9851aa97-f279-48de-a37b-d025554d5172",
   "metadata": {},
   "source": [
    "# Train The Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train models\n",
    "##YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc64a35-f20f-4ce2-9eb9-9ed434c78e7f",
   "metadata": {},
   "source": [
    "# Predict Probabilities\n",
    "\n",
    "# #Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1dd68-a85c-44dd-b0a0-45fa31a4b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Predictions\n",
    "## YOUR CODE HERE\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model WITH Gender\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Gender', y='Pred_with_gender', data=)\n",
    "plt.title('Predicted Probability of Shortlisting (Model WITH Gender)')\n",
    "plt.show()\n",
    "\n",
    "# Model WITHOUT Gender\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Gender', y='Pred_without_gender', data= )\n",
    "plt.title('Predicted Probability of Shortlisting (Model WITHOUT Gender)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fa7bd-02b3-4d68-b29d-d213227c3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate Model:\n",
    "\n",
    "## Your code here\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Model WITH Gender\n",
    "print(\"Accuracy (With Gender):\", accuracy_score())\n",
    "print(\"Confusion Matrix (With Gender):\\n\", confusion_matrix(y_test, ))\n",
    "print(\"AUC (With Gender):\", roc_auc_score())\n",
    "\n",
    "# Model WITHOUT Gender\n",
    "print(\"Accuracy (Without Gender):\", accuracy_score())\n",
    "print(\"Confusion Matrix (Without Gender):\\n\", confusion_matrix()))\n",
    "print(\"AUC (Without Gender):\", roc_auc_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35c55e-fa1b-4c7c-a337-8b072145a9de",
   "metadata": {},
   "source": [
    "## Analysis Questions\n",
    "\n",
    "1. Did you observe any bias in the modelâ€™s predictions?\n",
    "2. How did removing gender affect the predictions?\n",
    "3. What ethical concerns arise when using sensitive attributes like gender?\n",
    "4. What would you recommend to mitigate bias in hiring models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
